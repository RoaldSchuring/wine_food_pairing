{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/roald/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/roald/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "# from operator import itemgetter\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(143754, 23)\n"
     ]
    }
   ],
   "source": [
    "base_location = r\"wine_data\"\n",
    "\n",
    "i = 0\n",
    "for file in os.listdir(base_location):\n",
    "    file_location = base_location + '/' + str(file)\n",
    "    if i==0:\n",
    "        wine_dataframe = pd.read_csv(file_location, encoding='latin-1')\n",
    "        i+=1\n",
    "    else:\n",
    "        df_to_append = pd.read_csv(file_location, encoding='latin-1', low_memory=False)\n",
    "        wine_dataframe = pd.concat([wine_dataframe, df_to_append], axis=0)\n",
    "\n",
    "wine_dataframe.drop_duplicates(subset=['Name'], inplace=True)\n",
    "\n",
    "geographies = ['Subregion', 'Region', 'Province', 'Country']\n",
    "\n",
    "for geo in geographies:\n",
    "    wine_dataframe[geo] = wine_dataframe[geo].apply(lambda x : str(x).strip())\n",
    "\n",
    "print(wine_dataframe.shape)"
   ]
  },
  {
   "source": [
    "Then, the food dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(568454, 10)\n"
     ]
    }
   ],
   "source": [
    "food_review_dataset = pd.read_csv('food_data/Reviews.csv')\n",
    "print(food_review_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training our Word Embeddings\n",
    "\n",
    "First, we need to train a Word2Vec model on all the words in our corpus. We will process our wine and food terms separately - some of the wine terms will be standardized to account for commonalities in the colorful language of the world of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews_list = list(wine_dataframe['Description'])\n",
    "food_reviews_list = list(food_review_dataset['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we need to tokenize the terms in our corpus (wine and food)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Grenache is not known as the most ageworthy wine, but this bottling boasts all the bones to make it happen.', 'Elegant aromas of boysenberry, lavender and dried red flowers lead into a tightly woven palate that combines ripe berries with gravelly minerality and stiff tannins.']\n['I have bought several of the Vitality canned dog food products and have found them all to be of good quality.', 'The product looks more like a stew than a processed meat and it smells better.']\n"
     ]
    }
   ],
   "source": [
    "full_wine_reviews_list = [str(r) for r in wine_reviews_list]\n",
    "full_wine_corpus = ' '.join(full_wine_reviews_list)\n",
    "wine_sentences_tokenized = sent_tokenize(full_wine_corpus)\n",
    "\n",
    "full_food_reviews_list = [str(r) for r in food_reviews_list]\n",
    "full_food_corpus = ' '.join(full_food_reviews_list)\n",
    "food_sentences_tokenized = sent_tokenize(full_food_corpus)\n",
    "\n",
    "print(wine_sentences_tokenized[:2])\n",
    "print(food_sentences_tokenized[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the text in each sentence is normalized (tokenize, remove punctuation and remove stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "punctuation_table = str.maketrans({key: None for key in string.punctuation})\n",
    "sno = SnowballStemmer('english')\n",
    "\n",
    "def normalize_text(raw_text):\n",
    "    try:\n",
    "        word_list = word_tokenize(raw_text)\n",
    "        normalized_sentence = []\n",
    "        for w in word_list:\n",
    "            try:\n",
    "                w = str(w)\n",
    "                lower_case_word = str.lower(w)\n",
    "                stemmed_word = sno.stem(lower_case_word)\n",
    "                no_punctuation = stemmed_word.translate(punctuation_table)\n",
    "                if len(no_punctuation) > 1 and no_punctuation not in stop_words:\n",
    "                    normalized_sentence.append(no_punctuation)\n",
    "            except:\n",
    "                continue\n",
    "        return normalized_sentence\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "normalized_wine_sentences = []\n",
    "for s in wine_sentences_tokenized:\n",
    "    normalized_text = normalize_text(s)\n",
    "    normalized_wine_sentences.append(normalized_text)\n",
    "\n",
    "normalized_food_sentences = []\n",
    "for s in food_sentences_tokenized:\n",
    "    normalized_text = normalize_text(s)\n",
    "    normalized_food_sentences.append(normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of the terms we are interested in are single words. Some of the terms are phrases, consisting of two (or more!) words. An example of this might be 'high tannin'. We can use gensim's Phrases feature to extract all the most relevant bi- and tri-grams from our corpus.\n",
    "\n",
    "We will train a separate trigram model for wine and for food. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, take care of the wine trigrams\n",
    "# wine_bigram_model = Phrases(normalized_wine_sentences, min_count=100)\n",
    "# wine_bigrams = [wine_bigram_model[line] for line in normalized_wine_sentences]\n",
    "# wine_trigram_model = Phrases(wine_bigrams, min_count=50)\n",
    "# phrased_wine_sentences = [wine_trigram_model[line] for line in wine_bigrams]\n",
    "# wine_trigram_model.save('wine_trigrams.pkl')\n",
    "\n",
    "### now, do the same for food\n",
    "food_bigram_model = Phrases(normalized_food_sentences, min_count=100)\n",
    "food_bigrams = [food_bigram_model[sent] for sent in normalized_food_sentences]\n",
    "food_trigram_model = Phrases(food_bigrams, min_count=50)\n",
    "phrased_food_sentences = [food_trigram_model[sent] for sent in food_bigrams]\n",
    "food_trigram_model.save('food_trigrams.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the trigram model has already been trained, simply retrieve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_trigram_model = Phraser.load('wine_trigrams.pkl')\n",
    "food_trigram_model = Phraser.load('food_trigrams.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the most important part: leveraging existing wine theory, the work of others like Bernard Chen, wine descriptor mappings and the UC Davis wine wheel, the top 5000 most frequent wine terms were reviewed to (i) determine whether they are a descriptor that can be derived by blind tasting, and (ii) whether they are informative (judgments like 'tasty' and 'great' are not considered to be informative). The roughly 1000 descriptors that remain were then mapped onto a normalized descriptor, a category and a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_mapping = pd.read_csv('descriptor_mapping.csv', encoding='latin1').set_index('raw descriptor')\n",
    "\n",
    "def return_mapped_descriptor(word, mapping):\n",
    "    if word in list(mapping.index):\n",
    "        normalized_word = mapping.at[word, 'level_3']\n",
    "        return normalized_word\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "normalized_wine_sentences = []\n",
    "for sent in phrased_wine_sentences:\n",
    "    normalized_wine_sentence = []\n",
    "    for word in sent:\n",
    "        normalized_word = return_mapped_descriptor(word, descriptor_mapping)\n",
    "        normalized_wine_sentence.append(str(normalized_word))\n",
    "    normalized_wine_sentences.append(normalized_wine_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through the same process for food, but without normalizing the nonaroma descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "aroma_descriptor_mapping = descriptor_mapping.loc[descriptor_mapping['type'] == 'aroma']\n",
    "normalized_food_sentences = []\n",
    "for sent in phrased_food_sentences:\n",
    "    normalized_food_sentence = []\n",
    "    for word in sent:\n",
    "        normalized_word = return_mapped_descriptor(word, aroma_descriptor_mapping)\n",
    "        normalized_food_sentence.append(str(normalized_word))\n",
    "    normalized_food_sentences.append(normalized_food_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's combine the wine dataset with our food dataset so we can train our embeddings. We want to make sure that the food and wine embeddings are calculated in the same feature space so that we can compute similarity vectors later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_sentences = normalized_wine_sentences + normalized_food_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to train our Word2Vec model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=37276, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "wine_word2vec_model = Word2Vec(normalized_sentences, size=300, min_count=8, iter=15)\n",
    "print(wine_word2vec_model)\n",
    "\n",
    "wine_word2vec_model.save('food_word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the word2vec model has already been trained, simply load it\n",
    "wine_word2vec_model = Word2Vec.load(\"food_word2vec_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing our Wine Dataset\n",
    "\n",
    "We can now turn our attention to our wine dataset. Descriptions for a single wine are unlikely to contain sufficient information about all the nonaromas and aromas to yield consistent and reliable pairing recommendations. As such, we will produce recommendations at the grape variety & subregion level. \n",
    "\n",
    "First, let's normalize the names of the grape varieties in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_mapping = {'Shiraz': 'Syrah', 'Pinot Gris': 'Pinot Grigio', 'Pinot Grigio/Gris': 'Pinot Grigio', \n",
    "                   'Garnacha, Grenache': 'Grenache', 'Garnacha': 'Grenache', 'CarmenÃ¨re': 'Carmenere',\n",
    "                    'GrÃ¼ner Veltliner': 'Gruner Veltliner', 'TorrontÃ©s': 'Torrontes', \n",
    "                   'RhÃ´ne-style Red Blend': 'Rhone-style Red Blend', 'AlbariÃ±o': 'Albarino',\n",
    "                  'GewÃ¼rztraminer': 'Gewurztraminer', 'RhÃ´ne-style White Blend': 'Rhone-style White Blend',\n",
    "                  'SpÃƒÂ¤tburgunder, Pinot Noir': 'Pinot Noir', 'Sauvignon, Sauvignon Blanc': 'Sauvignon Blanc',\n",
    "                  'Pinot Nero, Pinot Noir': 'Pinot Noir', 'Malbec-Merlot, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend',\n",
    "                  'Meritage, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend', 'Garnacha, Grenache': 'Grenache',\n",
    "                   'FumÃ© Blanc': 'Sauvignon Blanc', 'Cabernet Sauvignon-Cabernet Franc, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend',\n",
    "                   'Cabernet Merlot, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend', 'Cabernet Sauvignon-Merlot, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend',\n",
    "                   'Cabernet Blend, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend', 'Malbec-Cabernet Sauvignon, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend',\n",
    "                   'Merlot-Cabernet Franc, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend', 'Merlot-Cabernet Sauvignon, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend',\n",
    "                   'Cabernet Franc-Merlot, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend', 'Merlot-Malbec, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend',\n",
    "                   'Cabernet, Bordeaux-style Red Blend': 'Bordeaux-style Red Blend', 'Primitivo, Zinfandel': 'Zinfandel',\n",
    "                   'AragonÃªs, Tempranillo': 'Aragonez, Tempranillo'\n",
    "                  }\n",
    "\n",
    "def consolidate_varieties(variety_name):\n",
    "    if variety_name in variety_mapping:\n",
    "        return variety_mapping[variety_name]\n",
    "    else:\n",
    "        return variety_name\n",
    "\n",
    "wine_df_clean = wine_dataframe.copy()\n",
    "wine_df_clean['Variety'] = wine_df_clean['Variety'].apply(consolidate_varieties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the set of geography subregions we will use to define our wines. Not too general, not too specific... just right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_of_geographies = ['Subregion', 'Region', 'Province', 'Country']\n",
    "\n",
    "# replace any nan values in the geography columns with the word none\n",
    "def replace_nan_for_zero(value):\n",
    "    if str(value) == '0' or str(value) == 'nan':\n",
    "        return 'none'\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "for o in order_of_geographies:\n",
    "    wine_df_clean[o] = wine_df_clean[o].apply(replace_nan_for_zero)\n",
    "\n",
    "wine_df_clean.loc[:, order_of_geographies].fillna('none', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_geo = wine_df_clean.groupby(['Variety', 'Country', 'Province', 'Region', 'Subregion']).size().reset_index().rename(columns={0:'count'})\n",
    "variety_geo_sliced = variety_geo.loc[variety_geo['count'] > 1]\n",
    "\n",
    "vgeos_df = pd.DataFrame(variety_geo_sliced, columns=['Variety', 'Country', 'Province', 'Region', 'Subregion', 'count']) \n",
    "vgeos_df.to_csv('varieties_all_geos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140615, 7)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variety_geo_df = pd.read_csv('varieties_all_geos_normalized.csv', index_col=0)\n",
    "\n",
    "wine_df_merged = pd.merge(left=wine_df_clean, right=variety_geo_df, left_on=['Variety', 'Country', 'Province', 'Region', 'Subregion'],\n",
    "                         right_on=['Variety', 'Country', 'Province', 'Region', 'Subregion'])\n",
    "wine_df_merged.drop(['Unnamed: 0', 'Appellation', 'Bottle Size', 'Category', 'Country', \n",
    "                     'Date Published', 'Designation', 'Importer', 'Province', 'Rating', \n",
    "                     'Region', 'Reviewer', 'Reviewer Twitter Handle', 'Subregion', 'User Avg Rating', 'Winery', 'count'], \n",
    "                    axis=1, inplace=True)\n",
    "wine_df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want to keep wine types (location + variety) that appear frequently enough in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119527, 4)\n"
     ]
    }
   ],
   "source": [
    "variety_geos = wine_df_merged.groupby(['Variety', 'geo_normalized']).size()\n",
    "at_least_n_types = variety_geos[variety_geos > 30].reset_index()\n",
    "wine_df_merged_filtered = pd.merge(wine_df_merged, at_least_n_types, left_on=['Variety', 'geo_normalized'], right_on=['Variety', 'geo_normalized'])\n",
    "wine_df_merged_filtered = wine_df_merged_filtered[['Name', 'Variety', 'geo_normalized', 'Description']]\n",
    "print(wine_df_merged_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will extract 7 vectors for every wine:\n",
    "\n",
    "- aroma vector (the aggregate of all the aroma descriptors in a wine)\n",
    "- nonaroma vectors (an aggregate vector for only aroma & non-aroma descriptors matching the core tastes below):\n",
    "    - sweetness\n",
    "    - acid\n",
    "    - salt\n",
    "    - piquant\n",
    "    - fat\n",
    "    - bitter\n",
    "    \n",
    " In our descriptor file, we have defined which normalized descriptors pertain to each nonaroma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = list(wine_df_merged_filtered['Description'])\n",
    "\n",
    "descriptor_mapping = pd.read_csv('descriptor_mapping_tastes.csv', encoding='latin1').set_index('raw descriptor')\n",
    "\n",
    "core_tastes = ['aroma', 'weight', 'sweet', 'acid', 'salt', 'piquant', 'fat', 'bitter']\n",
    "descriptor_mappings = dict()\n",
    "for c in core_tastes:\n",
    "    if c=='aroma':\n",
    "        descriptor_mapping_filtered=descriptor_mapping.loc[descriptor_mapping['type']=='aroma']\n",
    "    else:\n",
    "        descriptor_mapping_filtered=descriptor_mapping.loc[descriptor_mapping['primary taste']==c]\n",
    "    descriptor_mappings[c] = descriptor_mapping_filtered                                                   \n",
    "    \n",
    "\n",
    "def return_descriptor_from_mapping(descriptor_mapping, word, core_taste):\n",
    "    if word in list(descriptor_mapping.index):\n",
    "        descriptor_to_return = descriptor_mapping['combined'][word]\n",
    "        return descriptor_to_return\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "review_descriptors = []\n",
    "for review in wine_reviews:\n",
    "    taste_descriptors = []\n",
    "    normalized_review = normalize_text(review)\n",
    "    phrased_review = wine_trigram_model[normalized_review]\n",
    "#     print(phrased_review)\n",
    "    \n",
    "    for c in core_tastes:                                                      \n",
    "        descriptors_only = [return_descriptor_from_mapping(descriptor_mappings[c], word, c) for word in phrased_review]\n",
    "        no_nones = [str(d).strip() for d in descriptors_only if d is not None]\n",
    "        descriptorized_review = ' '.join(no_nones)\n",
    "        taste_descriptors.append(descriptorized_review)\n",
    "    review_descriptors.append(taste_descriptors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take the list of descriptors for each wine and its aroma/nonaroma vectors and compute a TF-IDF weighted embedding for each. We will store the results in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aroma\n",
      "weight\n",
      "sweet\n",
      "acid\n",
      "salt\n",
      "piquant\n",
      "fat\n",
      "bitter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Variety</th>\n",
       "      <th>geo_normalized</th>\n",
       "      <th>Description</th>\n",
       "      <th>aroma_descriptors</th>\n",
       "      <th>weight_descriptors</th>\n",
       "      <th>sweet_descriptors</th>\n",
       "      <th>acid_descriptors</th>\n",
       "      <th>salt_descriptors</th>\n",
       "      <th>piquant_descriptors</th>\n",
       "      <th>fat_descriptors</th>\n",
       "      <th>bitter_descriptors</th>\n",
       "      <th>aroma</th>\n",
       "      <th>weight</th>\n",
       "      <th>sweet</th>\n",
       "      <th>acid</th>\n",
       "      <th>salt</th>\n",
       "      <th>piquant</th>\n",
       "      <th>fat</th>\n",
       "      <th>bitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michel Rolland Napa Valley 2014 MR Red (Napa V...</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Napa Valley, North Coast, California, USA</td>\n",
       "      <td>Made in partnership with Alpha Omega Winery's ...</td>\n",
       "      <td>[plum, cinnamon, oak]</td>\n",
       "      <td>[full_bodied, full_bodied]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[low_tannin]</td>\n",
       "      <td>[2.9548044, -0.7723141, -1.0630254, 0.95423204...</td>\n",
       "      <td>[4.686098, 2.5759785, -0.061426777, -1.0423864...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2.6357722, -1.2962552, 1.2999502, -2.173654, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soquel Vineyards 2015 Intreccio Library Select...</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Napa Valley, North Coast, California, USA</td>\n",
       "      <td>This is Cabernet Sauvignon-based with ample ad...</td>\n",
       "      <td>[licorice, plum]</td>\n",
       "      <td>[full_bodied, full_bodied, full_bodied]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5.8419256, 3.765644, 1.203867, 2.1082616, 2.0...</td>\n",
       "      <td>[4.686098, 2.5759785, -0.061426777, -1.0423864...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flora Springs 2016 Trilogy Red (Napa Valley)</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Napa Valley, North Coast, California, USA</td>\n",
       "      <td>The producer's long-standing Bordeaux-style bl...</td>\n",
       "      <td>[blueberry, coffee, vanilla, herb, root]</td>\n",
       "      <td>[full_bodied]</td>\n",
       "      <td>[dry]</td>\n",
       "      <td>[high_acid]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[high_tannin]</td>\n",
       "      <td>[0.48325795, 1.9394274, -0.9045641, -2.0776794...</td>\n",
       "      <td>[4.686098, 2.5759785, -0.061426777, -1.0423864...</td>\n",
       "      <td>[1.7074658, 6.6105576, 5.9967256, -0.48125347,...</td>\n",
       "      <td>[2.1475096, 3.69325, 1.9682618, -0.014646966, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3.9458117, 4.1582265, 2.1328716, -2.3177094, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Pozzan 2015 Marianna Red (Napa Valley)</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Napa Valley, North Coast, California, USA</td>\n",
       "      <td>This blends a majority of Cabernet Sauvignon w...</td>\n",
       "      <td>[plum, graphite, pencil_shaving]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[high_acid]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[high_tannin]</td>\n",
       "      <td>[3.6875446, 1.9251448, 1.5338858, -4.6782393, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2.1475096, 3.69325, 1.9682618, -0.014646966, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3.9458117, 4.1582265, 2.1328716, -2.3177094, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liparita 2016 Left Bank Reserve Red (Napa Valley)</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Napa Valley, North Coast, California, USA</td>\n",
       "      <td>This Cabernet Sauvignon-dominant blend is smok...</td>\n",
       "      <td>[smoke, chalk, fruit, herb, cedar, pencil_shav...</td>\n",
       "      <td>[full_bodied]</td>\n",
       "      <td>[dry]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[low_tannin]</td>\n",
       "      <td>[2.4731045, 2.9364963, 1.5034355, -0.511009, 5...</td>\n",
       "      <td>[4.686098, 2.5759785, -0.061426777, -1.0423864...</td>\n",
       "      <td>[1.7074658, 6.6105576, 5.9967256, -0.48125347,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2.6357722, -1.2962552, 1.2999502, -2.173654, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0  Michel Rolland Napa Valley 2014 MR Red (Napa V...   \n",
       "1  Soquel Vineyards 2015 Intreccio Library Select...   \n",
       "2       Flora Springs 2016 Trilogy Red (Napa Valley)   \n",
       "3     Michael Pozzan 2015 Marianna Red (Napa Valley)   \n",
       "4  Liparita 2016 Left Bank Reserve Red (Napa Valley)   \n",
       "\n",
       "                    Variety                             geo_normalized  \\\n",
       "0  Bordeaux-style Red Blend  Napa Valley, North Coast, California, USA   \n",
       "1  Bordeaux-style Red Blend  Napa Valley, North Coast, California, USA   \n",
       "2  Bordeaux-style Red Blend  Napa Valley, North Coast, California, USA   \n",
       "3  Bordeaux-style Red Blend  Napa Valley, North Coast, California, USA   \n",
       "4  Bordeaux-style Red Blend  Napa Valley, North Coast, California, USA   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Made in partnership with Alpha Omega Winery's ...   \n",
       "1  This is Cabernet Sauvignon-based with ample ad...   \n",
       "2  The producer's long-standing Bordeaux-style bl...   \n",
       "3  This blends a majority of Cabernet Sauvignon w...   \n",
       "4  This Cabernet Sauvignon-dominant blend is smok...   \n",
       "\n",
       "                                   aroma_descriptors  \\\n",
       "0                              [plum, cinnamon, oak]   \n",
       "1                                   [licorice, plum]   \n",
       "2           [blueberry, coffee, vanilla, herb, root]   \n",
       "3                   [plum, graphite, pencil_shaving]   \n",
       "4  [smoke, chalk, fruit, herb, cedar, pencil_shav...   \n",
       "\n",
       "                        weight_descriptors sweet_descriptors acid_descriptors  \\\n",
       "0               [full_bodied, full_bodied]                []               []   \n",
       "1  [full_bodied, full_bodied, full_bodied]                []               []   \n",
       "2                            [full_bodied]             [dry]      [high_acid]   \n",
       "3                                       []                []      [high_acid]   \n",
       "4                            [full_bodied]             [dry]               []   \n",
       "\n",
       "  salt_descriptors piquant_descriptors fat_descriptors bitter_descriptors  \\\n",
       "0               []                  []              []       [low_tannin]   \n",
       "1               []                  []              []                 []   \n",
       "2               []                  []              []      [high_tannin]   \n",
       "3               []                  []              []      [high_tannin]   \n",
       "4               []                  []              []       [low_tannin]   \n",
       "\n",
       "                                               aroma  \\\n",
       "0  [2.9548044, -0.7723141, -1.0630254, 0.95423204...   \n",
       "1  [5.8419256, 3.765644, 1.203867, 2.1082616, 2.0...   \n",
       "2  [0.48325795, 1.9394274, -0.9045641, -2.0776794...   \n",
       "3  [3.6875446, 1.9251448, 1.5338858, -4.6782393, ...   \n",
       "4  [2.4731045, 2.9364963, 1.5034355, -0.511009, 5...   \n",
       "\n",
       "                                              weight  \\\n",
       "0  [4.686098, 2.5759785, -0.061426777, -1.0423864...   \n",
       "1  [4.686098, 2.5759785, -0.061426777, -1.0423864...   \n",
       "2  [4.686098, 2.5759785, -0.061426777, -1.0423864...   \n",
       "3                                                NaN   \n",
       "4  [4.686098, 2.5759785, -0.061426777, -1.0423864...   \n",
       "\n",
       "                                               sweet  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [1.7074658, 6.6105576, 5.9967256, -0.48125347,...   \n",
       "3                                                NaN   \n",
       "4  [1.7074658, 6.6105576, 5.9967256, -0.48125347,...   \n",
       "\n",
       "                                                acid salt piquant  fat  \\\n",
       "0                                                NaN  NaN     NaN  NaN   \n",
       "1                                                NaN  NaN     NaN  NaN   \n",
       "2  [2.1475096, 3.69325, 1.9682618, -0.014646966, ...  NaN     NaN  NaN   \n",
       "3  [2.1475096, 3.69325, 1.9682618, -0.014646966, ...  NaN     NaN  NaN   \n",
       "4                                                NaN  NaN     NaN  NaN   \n",
       "\n",
       "                                              bitter  \n",
       "0  [2.6357722, -1.2962552, 1.2999502, -2.173654, ...  \n",
       "1                                                NaN  \n",
       "2  [3.9458117, 4.1582265, 2.1328716, -2.3177094, ...  \n",
       "3  [3.9458117, 4.1582265, 2.1328716, -2.3177094, ...  \n",
       "4  [2.6357722, -1.2962552, 1.2999502, -2.173654, ...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taste_descriptors = []\n",
    "taste_vectors = []\n",
    "\n",
    "for n, taste in enumerate(core_tastes):\n",
    "    print(taste)\n",
    "    taste_words = [r[n] for r in review_descriptors]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit(taste_words)\n",
    "    dict_of_tfidf_weightings = dict(zip(X.get_feature_names(), X.idf_))\n",
    "        \n",
    "    wine_review_descriptors = []\n",
    "    wine_review_vectors = []\n",
    "    \n",
    "    for d in taste_words:\n",
    "        descriptor_count = 0\n",
    "        weighted_review_terms = []\n",
    "        terms = d.split(' ')\n",
    "        for term in terms:\n",
    "            if term in dict_of_tfidf_weightings.keys():\n",
    "                tfidf_weighting = dict_of_tfidf_weightings[term]\n",
    "                try:\n",
    "                    word_vector = wine_word2vec_model.wv.get_vector(term).reshape(1, 300)\n",
    "                    weighted_word_vector = tfidf_weighting * word_vector\n",
    "                    weighted_review_terms.append(weighted_word_vector)\n",
    "                    descriptor_count += 1\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "        try:\n",
    "            review_vector = sum(weighted_review_terms)/len(weighted_review_terms)\n",
    "            review_vector = review_vector[0]\n",
    "        except:\n",
    "            review_vector = np.nan\n",
    "#         terms_and_vec = [terms, review_vector]\n",
    "        wine_review_vectors.append(review_vector)\n",
    "        wine_review_descriptors.append(terms)\n",
    "    \n",
    "    taste_vectors.append(wine_review_vectors)\n",
    "    taste_descriptors.append(wine_review_descriptors)\n",
    "    \n",
    "\n",
    "taste_vectors_t = list(map(list, zip(*taste_vectors)))\n",
    "taste_descriptors_t = list(map(list, zip(*taste_descriptors)))\n",
    "\n",
    "review_vecs_df = pd.DataFrame(taste_vectors_t, columns=core_tastes)\n",
    "\n",
    "columns_taste_descriptors = [a + '_descriptors' for a in core_tastes]\n",
    "review_descriptors_df = pd.DataFrame(taste_descriptors_t, columns=columns_taste_descriptors)\n",
    "\n",
    "wine_df_vecs = pd.concat([wine_df_merged_filtered, review_descriptors_df, review_vecs_df], axis=1)\n",
    "wine_df_vecs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't have a nonaroma embedding for one of the wines, we will simply take the average nonaroma embedding for all the wines in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the average embedding for the wine attribute across all wines. \n",
    "avg_taste_vecs = dict()\n",
    "for t in core_tastes:\n",
    "    # look at the average embedding for a taste, across all wines that have descriptors for that taste \n",
    "    review_arrays = wine_df_vecs[t].dropna()\n",
    "    average_taste_vec = np.average(review_arrays)\n",
    "    avg_taste_vecs[t] = average_taste_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the average embedding for each type of wine (aromas and all nonaromas). We have defined the different types of wines by grape variety and geography, keeping only those with a sufficiently large sample size.\n",
    "\n",
    "For each variety, we will pull (i) a 300-dimensional aroma vector, and (ii) 7 non-aroma scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_geos = list(set(zip(wine_df_vecs['Variety'], wine_df_vecs['geo_normalized'])))\n",
    "\n",
    "def subset_wine_vectors(list_of_varieties, wine_attribute):\n",
    "    wine_variety_vectors = []\n",
    "    for v in list_of_varieties:\n",
    "\n",
    "        one_var_only = wine_df_vecs.loc[(wine_df_vecs['Variety'] == v[0]) & \n",
    "                                                (wine_df_vecs['geo_normalized'] == v[1])]\n",
    "        if len(list(one_var_only.index)) < 1 or str(v[1][-1]) == '0':\n",
    "            continue\n",
    "        else:\n",
    "            taste_vecs = list(one_var_only[wine_attribute])\n",
    "            taste_vecs = [avg_taste_vecs[wine_attribute] if 'numpy' not in str(type(x)) else x for x in taste_vecs]\n",
    "            average_variety_vec = np.average(taste_vecs, axis=0)\n",
    "            \n",
    "            descriptor_colname = wine_attribute + '_descriptors'\n",
    "            all_descriptors = [i[0] for i in list(one_var_only[descriptor_colname])]\n",
    "            word_freqs = Counter(all_descriptors)\n",
    "            most_common_words = word_freqs.most_common(50)\n",
    "            top_n_words = [(i[0], \"{:.2f}\".format(i[1]/len(taste_vecs))) for i in most_common_words]\n",
    "            top_n_words = [i for i in top_n_words if len(i[0])>2]\n",
    "            wine_variety_vector = [v, average_variety_vec, top_n_words]\n",
    "                \n",
    "            wine_variety_vectors.append(wine_variety_vector)\n",
    "            \n",
    "    return wine_variety_vectors\n",
    "\n",
    "\n",
    "def pca_wine_variety(list_of_varieties, wine_attribute, pca=True):\n",
    "    wine_var_vectors = subset_wine_vectors(normalized_geos, wine_attribute)\n",
    "    \n",
    "    wine_varieties = [str(w[0]).replace('(', '').replace(')', '').replace(\"'\", '').replace('\"', '') for w in wine_var_vectors]\n",
    "    wine_var_vec = [w[1] for w in wine_var_vectors]\n",
    "    if pca:\n",
    "        pca = PCA(1)\n",
    "        wine_var_vec = pca.fit_transform(wine_var_vec)\n",
    "        wine_var_vec = pd.DataFrame(wine_var_vec, index=wine_varieties)\n",
    "    else:\n",
    "        wine_var_vec = pd.Series(wine_var_vec, index=wine_varieties)\n",
    "    wine_var_vec.sort_index(inplace=True)\n",
    "    \n",
    "    wine_descriptors = pd.DataFrame([w[2] for w in wine_var_vectors], index=wine_varieties)\n",
    "    wine_descriptors = pd.melt(wine_descriptors.reset_index(), id_vars='index')\n",
    "    wine_descriptors.sort_index(inplace=True)\n",
    "    \n",
    "    return wine_var_vec, wine_descriptors\n",
    "\n",
    "taste_dataframes = []\n",
    "# generate the dataframe of aromas vectors as output, \n",
    "aroma_vec, aroma_descriptors = pca_wine_variety(normalized_geos, 'aroma', pca=False)\n",
    "taste_dataframes.append(aroma_vec)\n",
    "\n",
    "# generate the dataframes of nonaroma scalars\n",
    "for tw in core_tastes[1:]:\n",
    "    pca_w_dataframe, nonaroma_descriptors = pca_wine_variety(normalized_geos, tw, pca=True)\n",
    "    taste_dataframes.append(pca_w_dataframe)\n",
    "    \n",
    "# combine all the dataframes created above into one \n",
    "all_nonaromas = pd.concat(taste_dataframes, axis=1)\n",
    "all_nonaromas.columns = core_tastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the 50 top descriptors for each wine variety as a CSV file. We will us this later to dig deeper into our proposed wine recommendations.\n",
    "\n",
    "aroma_descriptors_copy = aroma_descriptors.copy()\n",
    "aroma_descriptors_copy.set_index('index', inplace=True)\n",
    "aroma_descriptors_copy.dropna(inplace=True)\n",
    "\n",
    "aroma_descriptors_copy = pd.DataFrame(aroma_descriptors_copy['value'].tolist(), index=aroma_descriptors_copy.index)\n",
    "aroma_descriptors_copy.columns = ['descriptors', 'relative_frequency']\n",
    "aroma_descriptors_copy.to_csv('wine_variety_descriptors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, it's hard to interpret the nonaroma scalars. To allow for greater interpretability, we will normalize the nonaroma scalars between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "sweet\n",
      "acid\n",
      "salt\n",
      "piquant\n",
      "fat\n",
      "bitter\n"
     ]
    }
   ],
   "source": [
    "def normalize(df, cols_to_normalize):\n",
    "    for feature_name in cols_to_normalize:\n",
    "        print(feature_name)\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: (x- min_value)/(max_value-min_value))\n",
    "#         (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return df\n",
    "\n",
    "all_nonaromas_normalized = normalize(all_nonaromas, cols_to_normalize=core_tastes[1:])\n",
    "all_nonaromas_normalized.to_csv('wine_aromas_nonaromas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparing our Food Dataset\n",
    "\n",
    "Now that we have our wine aroma vectors and the nonaroma scalars, we can turn our attention to food. \n",
    "\n",
    "We will want to generate nonaroma vectors for any type of food that we want a wine pairing with. For food, we don't have the luxury of being able to define nonaroma vs. aroma descriptors, so the approach we take will be slightly different:\n",
    "\n",
    "The aroma vector will be the full food embedding.\n",
    "\n",
    "We will define an embedding for each of our core nonaromas (sweet, acid, salt, piquant, fat and bitter), and the weight/body of the food. We will define the maximum distance between each of the nonaroma embeddings and a range of commonly appearing foods. The foods that least and most resemble each nonaroma will eventually allow us to create a normalized scale between 0 (very dissimilar) and 1 (very similar) to say how much a food reflects each nonaroma. \n",
    "\n",
    "First, let's load this list of common foods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.read_csv('list_of_foods.csv')\n",
    "foods_list = list(foods['Food'])\n",
    "foods_list_normalized = [normalize_text(f) for f in foods_list]\n",
    "foods_list_preprocessed = [food_trigram_model[f][0] for f in foods_list_normalized]\n",
    "foods_list_preprocessed = list(set(foods_list_preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the word embedding for each food in the list of sample foods, and save to a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods_vecs = dict()\n",
    "\n",
    "word_vectors = wine_word2vec_model.wv\n",
    "for f in foods_list_preprocessed:\n",
    "    try:\n",
    "        food_vec = word_vectors[f]\n",
    "        foods_vecs[f] = food_vec\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define the nonaroma embeddings + the weight embedding as the average of foods that represent each nonaroma characteristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "core_tastes_revised = {'weight': ['heavy', 'cassoulet', 'cassoulet', 'full_bodied', 'thick', 'milk', 'fat', 'mincemeat', 'steak', 'bold', 'pizza', 'pasta', 'creamy', 'bread'],\n",
    "                       'sweet': ['sweet', 'sugar', 'cake', 'mango', 'stevia'], \n",
    "                       'acid': ['acid', 'sour', 'vinegar', 'yoghurt', 'cevich', 'cevich'],\n",
    "                       'salt': ['salty', 'salty', 'parmesan', 'oyster', 'pizza', 'bacon', 'cured_meat', 'sausage', 'potato_chip'], \n",
    "                       'piquant': ['spicy'], \n",
    "                       'fat': ['fat', 'fried', 'creamy', 'cassoulet', 'foie_gras', 'buttery', 'cake', 'foie_gras', 'sausage', 'brie', 'carbonara'], \n",
    "                       'bitter': ['bitter', 'kale']\n",
    "                      }\n",
    "\n",
    "average_taste_vecs = dict()\n",
    "core_tastes_distances = dict()\n",
    "for taste, keywords in core_tastes_revised.items():\n",
    "    \n",
    "    all_keyword_vecs = []\n",
    "    for keyword in keywords:\n",
    "        c_vec = word_vectors[keyword]\n",
    "        all_keyword_vecs.append(c_vec)\n",
    "    \n",
    "    avg_taste_vec = np.average(all_keyword_vecs, axis=0)\n",
    "    average_taste_vecs[taste] = avg_taste_vec\n",
    "        \n",
    "    taste_distances = dict()\n",
    "    for k, v in foods_vecs.items():\n",
    "        similarity = 1- spatial.distance.cosine(avg_taste_vec, v)\n",
    "        taste_distances[k] = similarity\n",
    "        \n",
    "    core_tastes_distances[taste] = taste_distances        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find out which foods most and least resemble each nonaroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight dragonfruit pizza\n",
      "sweet mackerel honey\n",
      "acid biscuit citrus\n",
      "salt ice bacon\n",
      "piquant sole curri\n",
      "fat hungri foie_gras\n",
      "bitter biscuit kale\n"
     ]
    }
   ],
   "source": [
    "food_nonaroma_infos = dict()\n",
    "# for each core taste, identify the food item that is farthest and closest. We will need this to create a normalized scale between 0 and 1\n",
    "for key, value in core_tastes_revised.items():\n",
    "    dict_taste = dict()\n",
    "    farthest = min(core_tastes_distances[key], key=core_tastes_distances[key].get)\n",
    "    farthest_distance = core_tastes_distances[key][farthest]\n",
    "    closest = max(core_tastes_distances[key], key=core_tastes_distances[key].get)\n",
    "    closest_distance = core_tastes_distances[key][closest]\n",
    "    print(key, farthest, closest)\n",
    "    dict_taste['farthest'] = farthest_distance\n",
    "    dict_taste['closest'] = closest_distance\n",
    "    dict_taste['average_vec'] = average_taste_vecs[key]\n",
    "    food_nonaroma_infos[key] = dict_taste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's save the average embedding for each nonaroma, as well as the minimum and maximum distance to each nonaroma embedding - we will use these to scale the nonaroma scalars that we obtain for any foods we try to pair wine with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nonaroma_infos_df = pd.DataFrame(food_nonaroma_infos).T\n",
    "food_nonaroma_infos_df.to_csv('average_nonaroma_vectors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the pieces we need to build our wine recommendations. We will continue with this in a separate notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}